# ğŸ“„ Web Scraper - Sistema de DocumentaÃ§Ã£o Automatizada

Sistema avanÃ§ado de web scraping com interface grÃ¡fica para extraÃ§Ã£o e conversÃ£o de conteÃºdo web em documentaÃ§Ã£o estruturada em Markdown.

## ğŸ“‹ DescriÃ§Ã£o

Este projeto oferece uma soluÃ§Ã£o completa para extraÃ§Ã£o de conteÃºdo de sites e conversÃ£o automÃ¡tica para arquivos Markdown bem formatados. Ideal para criar documentaÃ§Ã£o local de APIs, tutoriais, artigos tÃ©cnicos e outros recursos web.

### CaracterÃ­sticas Principais

- **Interface GrÃ¡fica Intuitiva**: AplicaÃ§Ã£o desktop desenvolvida em Tkinter
- **ConversÃ£o Inteligente**: Utiliza Docling para conversÃ£o precisa de HTML para Markdown
- **Processamento em Lote**: Suporte para mÃºltiplas URLs simultaneamente
- **OrganizaÃ§Ã£o AutomÃ¡tica**: GeraÃ§Ã£o de Ã­ndices e estruturaÃ§Ã£o hierÃ¡rquica de arquivos
- **Arquitetura SOLID**: CÃ³digo modular, testÃ¡vel e extensÃ­vel
- **GestÃ£o de DependÃªncias**: Sistema de injeÃ§Ã£o de dependÃªncias para fÃ¡cil manutenÃ§Ã£o

## ğŸ—ï¸ Arquitetura

O projeto foi desenvolvido seguindo os princÃ­pios SOLID de design orientado a objetos:

- **Single Responsibility**: Cada classe possui uma Ãºnica responsabilidade bem definida
- **Open/Closed**: ExtensÃ­vel atravÃ©s de interfaces sem modificaÃ§Ã£o de cÃ³digo existente
- **Liskov Substitution**: ImplementaÃ§Ãµes podem ser substituÃ­das sem quebrar funcionalidades
- **Interface Segregation**: Interfaces especÃ­ficas e enxutas
- **Dependency Inversion**: DependÃªncia de abstraÃ§Ãµes, nÃ£o de implementaÃ§Ãµes concretas

Para mais detalhes sobre a arquitetura, consulte [SOLID_PRINCIPLES.md](SOLID_PRINCIPLES.md).

## ğŸ“¦ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### DependÃªncias

Instale as dependÃªncias necessÃ¡rias utilizando:

```bash
pip install -r requirements.txt
```

O arquivo `requirements.txt` contÃ©m:
- **beautifulsoup4**: Parser HTML/XML
- **docling**: Conversor de documentos para Markdown
- **requests**: Biblioteca HTTP

## ğŸš€ ExecuÃ§Ã£o

### Modo Interface GrÃ¡fica (Recomendado)

Execute a aplicaÃ§Ã£o atravÃ©s da interface grÃ¡fica:

```bash
python interface.py
```

**Nota sobre ExecuÃ§Ã£o**: O projeto foi desenvolvido para ser executado via script Python `.py` diretamente, nÃ£o como executÃ¡vel compilado. Isso permite maior flexibilidade e evita dependÃªncias de drivers externos (como webdriver para Selenium). Para facilitar o acesso, Ã© recomendado criar atalhos que abram o terminal no diretÃ³rio do projeto.

### ConfiguraÃ§Ã£o via Interface

1. **URLs**: Insira uma ou mais URLs dos sites a documentar
2. **Nome da Pasta**: Defina o nome da pasta de destino em `DOCUMENTAÃ‡ÃƒO/`
3. **Limite de PÃ¡ginas**: Configure o nÃºmero mÃ¡ximo de pÃ¡ginas a processar (1-1000)
4. **Selenium**: OpÃ§Ã£o desabilitada por padrÃ£o (requer configuraÃ§Ã£o adicional)

### Modo ProgramÃ¡tico

Para integraÃ§Ã£o em scripts ou automaÃ§Ãµes:

```python
from scrapper import SimpleWebScraper

# ConfiguraÃ§Ã£o bÃ¡sica
scraper = SimpleWebScraper(
    urls="https://exemplo.com.br",
    max_pages=50
)

# Executar scraping
scraper.run()
```

### Modo AvanÃ§ado com InjeÃ§Ã£o de DependÃªncias

```python
from scrapper import SimpleWebScraper, DoclingConverter

# Usar conversor customizado
custom_converter = DoclingConverter()
scraper = SimpleWebScraper(
    urls=["https://site1.com", "https://site2.com"],
    converter=custom_converter,
    max_pages=100
)

scraper.run()
```

## ğŸ“ Estrutura de SaÃ­da

```
DOCUMENTAÃ‡ÃƒO/
â””â”€â”€ nome_da_pasta/
    â”œâ”€â”€ index.md                    # Ãndice geral com todas as pÃ¡ginas
    â”œâ”€â”€ pagina_inicial.md           # ConteÃºdo convertido
    â”œâ”€â”€ documentacao_api.md
    â”œâ”€â”€ tutorial_01.md
    â””â”€â”€ ...
```

### Formato dos Arquivos Gerados

Cada arquivo Markdown contÃ©m:

```markdown
# TÃ­tulo da PÃ¡gina

**Fonte:** https://exemplo.com.br/pagina
**Data:** 2025-10-06 14:30:00

================================================================================

[ConteÃºdo extraÃ­do e convertido para Markdown]
```

### Arquivo de Ãndice

O `index.md` gerado automaticamente contÃ©m:

- Data e hora da extraÃ§Ã£o
- Lista de URLs de origem
- Total de pÃ¡ginas processadas
- Links para todos os arquivos gerados

## ğŸ”§ PersonalizaÃ§Ã£o

### Criar Conversor Customizado

```python
from scrapper import IContentConverter

class MeuConverter(IContentConverter):
    def convert(self, url: str) -> str:
        # ImplementaÃ§Ã£o personalizada
        return conteudo_markdown

# Usar conversor customizado
scraper = SimpleWebScraper(
    urls="https://exemplo.com",
    converter=MeuConverter()
)
```

### Modificar DiretÃ³rio de SaÃ­da

```python
scraper = SimpleWebScraper(urls="https://exemplo.com")
scraper.output_dir = "DOCS/minha_pasta"
scraper.run()
```

## ğŸ“‚ Estrutura do Projeto

```
simple-scrapper/
â”œâ”€â”€ interface.py              # Interface grÃ¡fica (Tkinter)
â”œâ”€â”€ scrapper.py              # LÃ³gica principal de scraping
â”œâ”€â”€ requirements.txt         # DependÃªncias do projeto
â”œâ”€â”€ LICENSE                  # LicenÃ§a MIT
â”œâ”€â”€ README.md               # Este arquivo
â”œâ”€â”€ SOLID_PRINCIPLES.md     # DocumentaÃ§Ã£o da arquitetura
â””â”€â”€ DOCUMENTAÃ‡ÃƒO/           # Pasta de saÃ­da (gerada automaticamente)
```

## ğŸ¯ Componentes Principais

### `interface.py`

- **InputValidator**: ValidaÃ§Ã£o de entradas do usuÃ¡rio
- **FolderManager**: Gerenciamento de pastas e diretÃ³rios
- **URLFieldManager**: Controle dinÃ¢mico de campos de URL
- **WebScraperGUI**: Interface grÃ¡fica principal

### `scrapper.py`

- **IContentConverter**: Interface para conversores de conteÃºdo
- **DoclingConverter**: ImplementaÃ§Ã£o usando biblioteca Docling
- **FileManager**: Gerenciamento de arquivos e nomenclatura
- **IndexGenerator**: GeraÃ§Ã£o de Ã­ndices
- **URLProcessor**: Processamento individual de URLs
- **SimpleWebScraper**: Orquestrador principal

## âš™ï¸ ConfiguraÃ§Ãµes

### Limites e Controles

- **max_pages**: Controla quantas pÃ¡ginas serÃ£o processadas (padrÃ£o: 100)
- **output_dir**: Define o diretÃ³rio de saÃ­da (padrÃ£o: nome baseado no domÃ­nio)
- **use_selenium**: Flag para habilitar Selenium (requer configuraÃ§Ã£o adicional)

### Tratamento de Erros

O sistema possui tratamento robusto de erros:
- Fallback automÃ¡tico em caso de falha de conversÃ£o
- Logs detalhados de todas as operaÃ§Ãµes
- ContinuaÃ§Ã£o do processamento mesmo com falhas individuais

## ğŸ› Troubleshooting

### Erro: "Nenhum conteÃºdo foi extraÃ­do"

**Causa**: O site pode estar bloqueando requisiÃ§Ãµes ou usando JavaScript pesado.

**SoluÃ§Ã£o**: 
- Verifique se a URL estÃ¡ acessÃ­vel no navegador
- Alguns sites requerem Selenium (requer configuraÃ§Ã£o adicional de webdriver)

### Erro: "MÃ³dulo nÃ£o encontrado"

**Causa**: DependÃªncias nÃ£o instaladas corretamente.

**SoluÃ§Ã£o**:
```bash
pip install -r requirements.txt
```

### Interface nÃ£o abre

**Causa**: Tkinter nÃ£o estÃ¡ instalado ou configurado.

**SoluÃ§Ã£o** (Ubuntu/Debian):
```bash
sudo apt-get install python3-tk
```

### Muitas dependÃªncias no ambiente

**Causa**: Ambiente Python com muitos pacotes instalados.

**SoluÃ§Ã£o**: Use ambiente virtual ou limpe dependÃªncias:
```bash
# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Instalar apenas dependÃªncias necessÃ¡rias
pip install -r requirements.txt
```

## ğŸ“Š Performance

- **Velocidade**: ~2-5 pÃ¡ginas por segundo (depende da conexÃ£o e site)
- **Uso de MemÃ³ria**: ~50-150 MB durante operaÃ§Ã£o
- **Armazenamento**: VariÃ¡vel conforme tamanho das pÃ¡ginas

## ğŸ” ConsideraÃ§Ãµes de Uso

### Uso Ã‰tico

- Respeite os termos de serviÃ§o dos sites
- Verifique o arquivo `robots.txt` do site
- Utilize delays apropriados entre requisiÃ§Ãµes
- NÃ£o sobrecarregue servidores com requisiÃ§Ãµes excessivas

### LimitaÃ§Ãµes

- NÃ£o processa conteÃºdo protegido por autenticaÃ§Ã£o
- Sites com JavaScript pesado podem requerer Selenium (configuraÃ§Ã£o adicional)
- Alguns sites implementam proteÃ§Ã£o contra scraping

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

### Diretrizes

- Siga os princÃ­pios SOLID jÃ¡ implementados
- Adicione testes para novas funcionalidades
- Mantenha a documentaÃ§Ã£o atualizada
- Utilize type hints em Python

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

```
MIT License - Copyright (c) 2025 Gabriel Lopes
```

## ğŸ‘¤ Autor

**Gabriel Lopes**

## ğŸ™ Agradecimentos

- **Docling**: Excelente biblioteca para conversÃ£o de documentos
- **BeautifulSoup**: Parser HTML robusto e confiÃ¡vel
- **Comunidade Python**: Pelo ecossistema rico de bibliotecas

## ğŸ“® Suporte

Para reportar bugs ou solicitar features, abra uma issue no repositÃ³rio do projeto.

---

**Desenvolvido com Python ğŸ | Interface com Tkinter | ConversÃ£o com Docling**
